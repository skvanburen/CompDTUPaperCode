{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 Menlo-Regular;\f2\fnil\fcharset0 Menlo-Bold;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;\red28\green0\blue207;
\red155\green35\blue147;\red14\green14\blue255;\red196\green26\blue22;\red0\green0\blue0;\red255\green255\blue255;
}
{\*\expandedcolortbl;;\csgenericrgb\c0\c0\c0\c85000;\csgenericrgb\c100000\c100000\c100000;\csgenericrgb\c11000\c0\c81000;
\csgenericrgb\c60759\c13753\c57628;\csgenericrgb\c5500\c5500\c100000;\csgenericrgb\c77000\c10200\c8600;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c100000;
}
\margl1440\margr1440\vieww20880\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Last updated April 3, 2020\
\
This first part of this file contains instructions on how to reproduce the power simulations from the paper. \
\
Commands 1-20 reproduce the permutation power analysis, while the instructions 21-23 will reproduce the Simulation based power analyses.  \
\
\
First, a few commands that may be useful for reproducing results on a slum based cluster:\
\
Open an interactive session of R/bash:\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f1 \cf2 \cb3 module load r/\cf4 3.6.0\cf2 \
srun -p interact -N \cf4 1\cf2  -n \cf4 1\cf2  --mem=\cf4 32\cf2 g --
\f2\b \cf5 time
\f1\b0 \cf2 =\cf4 8\cf2 :\cf4 00\cf2 :\cf4 00\cf2  --pty R --no-init-file\
\
srun -p interact -N \cf4 1\cf2  -n \cf4 1\cf2  --
\f2\b \cf5 time
\f1\b0 \cf2 =\cf4 8\cf2 :\cf4 00\cf2 :\cf4 00\cf2  --mem=\cf4 4\cf2 g --pty bash\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0 \cf0 \cb1 \
1. First, need to download the E-GEUV-1 data using the following lines, which end up running the R file DownloadGEUV1Data.R .  This array job has 924 parts because each job downloads one paired-end file and there are 462 samples (462*2=924)\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f2\b \cf5 \cb3 \

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\cf2 \
sbatch --array=\cf4 1-924\cf2  DownloadGEUV1Data.sh\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf0 \cb1 \
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 2. Then, generate the Salmon index that will be used in step 3 to quantify the data. This index is generated from gencodeV27 (for the reference transcripts only).  The necessary GENCODE files can be downloaded from 
\f1 \cf6 \cb3 https://www.gencodegenes.org/human/release_27.html\

\f0 \cf0 \cb1 \
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f1 \cf2 \cb3 sbatch -N \cf4 1\cf2  -n \cf4 1\cf2  --mem=\cf4 32\cf2 g --
\f2\b \cf5 time
\f1\b0 \cf2 =\cf4 2\cf2 :\cf4 00\cf2 :\cf4 00\cf2  -o /pine/scr/s/k/skvanbur/GEUV1/Salmon/indexlog.txt --wrap \cf7 "~/bin/Salmon0.11.3/bin/salmon index -p 1 -t gencode.v27.transcripts.fa.gz -i /pine/scr/s/k/skvanbur/GEUV1/SalmonBootSamps/transcripts_index --gencode"\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf0 \cb1 \
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf8 3. Next, run the Salmon quantifications themselves on all 462 samples using the following lines.  This code runs the R file \cb3 RunSalmonGEUV1Data.R
\f1 \cf2 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0 \cf0 \cb1  \
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f2\b \cf5 \cb3 \

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\cf2 \
sbatch --array=\cf4 1-462\cf2  RunSalmonGEUV1Data.sh\
\
\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf2 4. Next, create the the tx2gene data frame in r that matches transcripts to genes.  This will be needed by various downstream code. This code will not take too long to run, so can be run interactively or like this:
\f1 \
\
module load r/\cf4 3.6.0\cf2 \
sbatch -N \cf4 1\cf2  -n \cf4 1\cf2  --mem=\cf4 8\cf2 g --
\f2\b \cf5 time
\f1\b0 \cf2 =\cf4 2\cf2 :\cf4 00\cf2 :\cf4 00\cf2  -o /pine/scr/s/k/skvanbur/GEUV1/MakeTx2Gene.out --wrap \cf7 \'93Rscript \cf2 MakeTx2Gene.R\cf7 "\cf2  \
\
\
\
\

\f0 5. Next, save the Salmon output (not including bootstrap/Gibbs samples for now) and the key file containing the population membership of each sample to a .RData file for later use.  This file should not take long to run so can probably run interactively (using the command at the top of the file) or like this:\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f1 \cf2 module load r/\cf4 3.6.0
\f0 \cf2 \

\f1 sbatch -N \cf4 1\cf2  -n \cf4 1\cf2  --mem=\cf4 32\cf2 g --
\f2\b \cf5 time
\f1\b0 \cf2 =\cf4 2\cf2 :\cf4 00\cf2 :\cf4 00\cf2  -o /pine/scr/s/k/skvanbur/GEUV1/SaveSalmonDataAsRData.out --wrap \cf7 \'93Rscript \cf2 GEUV1SaveSalmonDataAsRData.R\cf7 "
\f0 \cf8 \
\
\
\
6. Next, run \'93SumToGene.R\'94 to summarize results to the gene level, both for counts and TPM values.  This file saves the data in two structures.  The abGene and cntGene files respectively contain transcripts on the rows and sample-specific expression values on the columns as well as average expression across gene/conditions, information on the highest expressed transcript across samples (major transcript), etc.  The abGene file contains TPM measurements, and the cntGene file contains counts and effective length measurements for each transcript/sample.  The abDatasets and cntDatasets files contain lists of data frames, with each data frame being reformatted data for each gene.  Specifically, in these data frames samples are on the rows and the columns contain transcript-level expression for a given sample.  The list of transcripts in these files will be all transcripts in the gene for any files saved with \'93NoOtherGroups\'94 in the name and  transcripts collapsed into other groups for files names \'93abDatasets.RData\'94 or \'93cntDatasets.RData\'94.  These other groups combine and transcript into an \'93Other\'94 category if the transcript has less than 5% of the overall gene-level expression.  We had originally used this as out filtering approach but switched to using DRIMSeq\'92s filtering procedure for all results the paper.  DRIMseq\'92s filtering procedure is implemented in the file \'93
\f1 \cf2 GEUV1FilterGenesForAnalysis.R\'94 
\f0 \cf8  below.  Make sure to set \'93OnlyCalculateAbundanceFromInfReps\'94  in the R file to FALSE initially. Additionally, the file can be submitted as an array job using the second command below to save the results for abundance data that is generated by taking the mean or median of bootstrap samples (using the option infRepStat in tximport) once it has been saved for the usual abundance estimates using the command above it.  To do this, make sure to set OnlyCalculateAbundanceFromInfReps to TRUE in the R file.\
\

\f2\b \cf5 \

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\cf2 \
sbatch -N \cf4 1\cf2  -n \cf4 1\cf2  --mem \cf4 16g\cf2  --
\f2\b \cf5 time
\f1\b0 \cf2 =\cf4 2\cf2 :\cf4 00\cf2 :\cf4 00\cf2  -o ~/res/GEUV1Data/SumToGene.txt --wrap \cf7 "Rscript SumToGene.R"\
\

\f2\b \cf5 \

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\cf2 \
sbatch --array=\cf4 1-4\cf2  SumToGene.sh\cf7 \
\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf8 7. Now, filter the output of \'93SumToGene.R\'94 from above using DRIMSeq\'92s filtering procedure.  First, run the top set of commands so save the filtered results for the regular abundance estimates.  Then, if desired, this job can be submitted as an array job using the second command below to save the filtered datasets for abundance data that is generated by taking the mean or median of bootstrap samples (using the option infRepStat in tximport) once it has been saved for the usual abundance estimates using the command above it.  This needs to be first completed for the usual abundance estimates because the list of transcripts that passes from the usual estimates is used as the set that passes for the abundance estimates calculated using the mean/median of bootstrap/gibbs samples to make comparisons between the different datasets as smooth as possible.\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f2\b \cf5 \

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\cf2 \
sbatch -N \cf4 1\cf2  -n \cf4 1\cf2  --mem \cf4 16g\cf2  --
\f2\b \cf5 time
\f1\b0 \cf2 =\cf4 4\cf2 :\cf4 00\cf2 :\cf4 00\cf2  -o ~/res/GEUV1Data/GEUV1FilterGenesForAnalysis.txt --wrap \cf7 "Rscript GEUV1FilterGenesForAnalysis.R"\
\

\f2\b \cf5 \

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\cf2 \
sbatch --array=\cf4 1-4\cf2  GEUV1FilterGenesForAnalysis.sh\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0
\cf7 \
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf8 8. Now, save the inferential replicates as separate .RData files for each biological sample.  Results need to be saved separately for each biological sample because otherwise the files get too large.  While the file is called \'93SaveGibbsDataAsRData.R\'94, it saves data for either bootstrap or Gibbs inferential replicates.\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f1 \cf2 \

\f2\b \cf5 \

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\cf2 \
sbatch --array=\cf4 1-462\cf2  SaveGibbsDataAsRData.sh\
\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf8 \cb9 9. Now, save full inferential replicate data files.  These files reorganize the files saved by \'93SaveGibbsDataAsRData.R\'94 to contain all inferential replicate values for all samples for all transcripts from a specific subset of genes.  To get this subset of genes, the full gene list that remains after filtering using DRIMSeq\'92s procedure is completed in the file \'93GEUV1FilterGenesForAnalysis.R\'94 is split up into 100 parts such that all 100 files taken together contain information for all genes that pass filtering. Results must be split up this way because otherwise the files are too large.\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f2\b \cf5 \cb3 \

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\cf2 \
sbatch --array=\cf4 1-100\cf2  GenerateFullInfRepDatasets.sh\
\
\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf2 10. Now, once the previous step has completed also save files that split results to be from a specific inferential replicate number for a specific chunk of the genes.  This will speed up code that modifies the datasets for the power analysis.
\f1 \
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf0 \cb1 \
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f2\b \cf5 \cb3 \

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\cf2 \
sbatch --array=\cf4 1-100\cf2  GenerateInfRepSpecificPartFullinfRepDatFiles.sh\
\
\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf2 11. Now, generate the files that are needed to run the power analysis on the data, including the group assignments and a necessary key file, etc with the file \'93GenerateValuesForPowerAnalysis1.R\'94.  This file will not take long to run so can be run interactively or like this:\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0
\cf0 \cb1 \
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f1 \cf2 \cb3 module load r/\cf4 3.6.0
\f0 \cf0 \cb1 \

\f1 \cf2 \cb3 sbatch -N \cf4 1\cf2  -n \cf4 1\cf2  --mem=\cf4 8\cf2 g --
\f2\b \cf5 time
\f1\b0 \cf2 =\cf4 2\cf2 :\cf4 00\cf2 :\cf4 00\cf2  -o /pine/scr/s/k/skvanbur/GEUV1/
\f0 GenerateValuesForPowerAnalysis1
\f1 .out --wrap \cf7 \'93Rscript 
\f0 \cf2 GenerateValuesForPowerAnalysis1
\f1 .R\cf7 \'94\cf2  \
\
\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf2 12. Now, update the datasets in accordance with the procedure described in the paper.  Each array value will run one of 100 parts (chunks) of genes.  Additionally, different change values (comparable to effect sizes) are run using different values.  Specifically, for the 100 total samples power analysis, array values 1-100 correspond to a change value of 4, 101-200 to a value of 1, 201-300 to a value of 2, and 301-400 to a value of 8.  Additionally, adding 1000 to the values generates the datasets for the 20 total sample power analysis (such that now array values 1001-1100 correspond to a change value of 4, 1101-1200 to a value of 1, 1201-1300 to a value of 2, and 1301-1400 to a value of 8). The code is structured in such a way that if the code does not complete, the job can be resubmitted and it will leave off at whichever file it was at before instead of starting from the beginning and overwriting files that are already there.
\f1 \
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f2\b \cf5 \

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\cf2 \
sbatch --array=\cf4 1-400\cf2 ,\cf4 1001-1400\cf2  updateilrMeansCovsAndabDatasets.sh\
\
\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf2 13. Now, run the power analyses for CompDTU and CompDTUme.  These results are executed and output by a file called \'93CompDTUMethodsPermutationPowerGEUV1Data.R\'94.  This file also contained code for alternative approaches (\'93ImputeAndPermute\'94 approaches) that we tried but did not end up putting in the paper.  Even still, this code runs the CompDTU and CompDTUme methods in addition to the CompMI approaches as well.  Setting TwentySamplesTotalAnalysis at the top of the file to be TRUE will run the results for the 20 sample total analysis, and setting it to FALSE will run the results for the 100 total sample analysis.  These is additionally an option called \'93SimulateData\'94 that is available even though the results for the simulated data are not run within this file.  The code to run the RSimulations from the paper can be found in the RSimulationCode folder.  Lastly, the multiple imputation based results in the supplement are run from this file by setting RunCompMIResults to be TRUE.  Setting this to TRUE will cause it to run the MI methods only and not run the CompDTU and CompDTUme results.  As a result, the MI values will run very quickly (usually less than 10-20 minutes for each array value), while the code can take more along the lines of 4-6 hours to run per array value if the ImputeAndPermute methods are being run.  The ImputeAndPermute methods are the ones that take the most time, and if you are only interested in the CompDTU and CompDTUme results you can and should set the option calcCompDTUandCompDTUmeOnly=TRUE in the function call.
\f1 \
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f2\b \cf5 \

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\
\cf2 sbatch --array=\cf4 1-30000\cf2  CompDTUMethodsPermutationPowerGEUV1Data.sh\
\
\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf2 14.  Now, run the DRIMSeq power analyses.  The default results presented in the paper add 1 to every count to greatly stabilize the DRIMSeq power results, though this option can be changed and theoretically shouldn\'92t be needed, especially if using the add_uniform=TRUE option.  Still, we found in many cases adding 1 to every count was needed to stabilize the results.
\f1 \
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f2\b \cf5 \

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\
\cf2 sbatch --array=\cf4 1-300\cf2  GEUV1DRIMSeqPower.sh\
\
\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf2 15. Now, run the RATs power analyses:
\f1 \
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f2\b \cf5 \

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\
\cf2 sbatch --array=\cf4 1-300\cf2  RATsPower.sh\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf2 16. Now, calculate the inferential variability of the genes on the ilr scale, which is used to group genes and results post hoc (but not by the method to determine significance directly).  These files need to be saved for the SummarizePowerResultsNewAug2019 results to work (otherwise, you can set useInfRV to FALSE in that file).  Set array_val equal to 2 for bootstrap samples (the default used in the paper) and 1 for Gibbs samples.
\f1 \
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f2\b \cf5 \
\

\f1\b0 \cf2 \
module load r/\cf4 3.6.0\cf2 \
sbatch --array=\cf4 2\cf2  CalculateInfRVGEUV1Data.sh\
\
\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf2 17. Now, run the file that calculates the overlap values for each gene.  This is done via the file \'93CalcTransOverlap.R\'94, which runs quickly such that it can be run interactively.\
\
\
\
\
18. Now, run the file that summarizes the power results for the various methods and calculate sens, spec, etc for all genes and various subsets of genes that are of interest.  The array values control the current method that is being run as well as the current change value being evaluated (ie values < 100 are for change value of 1, 101-200 are a change value of 2, etc).  Note that the results for the first two methods \'93Comp", "CompGibbsNewFeb2019" do not correspond to the most recent structure of power simulation for the CompDTU and CompDTUme methods such that these methods should not be specified.  Instead, specify the methods "CompDTUFromImputePermuteRes" and "CompDTUmeFromImputePermuteRes" since the most recent version of the CompDTU and CompDTUme power results come from these files.
\f1 \
\
\
module load r/\cf4 3.6.0\cf2 \
sbatch --array=\cf4 1-9\cf2 ,\cf4 101-109\cf2 ,\cf4 201-209\cf2 ,\cf4 301-309\cf2 ,\cf4 1001-1009\cf2 ,\cf4 1101-1109\cf2 ,\cf4 1201-1209\cf2  SummarizePowerResults.sh\
\

\f0 19. Once the results in the previous step have been completed, download the resulting files (from the \'93GEUV1PowerResBootDRIMSeqFiltering\'94 folder since use of bootstraps and DRIMSeq\'92s filtering procedure is the default) to your computer and generate the various ROC and other curves of interest using the file \'93GenerateROCCurves.R\'94.  Within this file you can change the change value and plotType being plotted and the methods being used/their colors, etc.  Additionally, note that changing SuppPlots to true will generate plots including methods presented in the supplement (ie including the RATs methods) and setting to FALSE will only include methods included in the supplement.\
\
20. Once all results have been run, run the file \'93SyncPaper1FiguresandTables.sh\'94 to copy the ROC curves generated in the previous step (which are saved in various directories) to the necessary paper directory.  This structure ensures the paper can be compiled even if all the other plots do not exist and ensures it can be compiled on a different computer.\
\
\
Now, instructions to reproduce the simulation power analysis.  The original version of this code is saved within the RSimulationCode directory within this folder such that no additional syncing of files from other locations is necessary.\
\
21. To run the simulation code, first run the file \'93ConstructRSimulationValues.R\'94.  This file specifies the parameter values for each simulation and saves these values in the data file RSimVals.RData.  This file can be run locally or interactively and takes very little time to run.\
\
22. Once the file above has completed, run the file RSimulationCode.sh (which in turn calls RSimulationCode.R) within the directory. Make sure to use this version and not an older one that may be backed up elsewhere.  This needs to be submitted as an array job, where each simulation setup is split up into parts to enable the code to run in parallel across different jobs.  Each job is currently split up such that each \'93part\'94 runs 1000 simulation runs, and each setup is currently run 10 times to give 10,000 total runs per setup.  Thus, each simulation scenario has 10 parts of results.  For example array values 1-10 correspond to simulation scenario 1 parts 1-10, values 101-110 correspond to scenario 2 parts 1-10, 201-210 correspond to scenario 3 parts 1-10, etc.  Thus values ending on 11-99 are not currently used and would be reserved to submit more parts for given scenarios.  The total number of simulation scenarios in the RSimVals.RData file is currently 714, which would require array value numbers greater than the maximum of about 40000 to be submitted.  To fix this, change the option RunAdditionalNSamps to TRUE and submit using array values corresponding to simulations 1-357 such that now values 1-10 correspond to simulation scenario 358 parts 1-10, values 101-110 correspond to scenario 359 parts 1-10, 201-210 correspond to scenario 360 parts 1-10, etc.  To submit these jobs to the cluster use code like the following, making sure to modify options such as RunAdditionalNSamps and and CalculateImputePermutePvals as necessary.  Declining to run the ImputePermute results (by setting CalculateImputePermutePvals=FALSE) speeds up computation time greatly and enables setting runs within each array value to 1000.  Previously, when I did want to run these ImputePermute results this runs of 1000 would have to be changed to 100 to get the results to compute in roughly the same amount of time.\
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f2\b \cf5 cd
\f1\b0 \cf2  ~/res/GEUV1Data/RSimulationCode\
module load r/\cf4 3.6.0\cf2 \

\f2\b \cf5 for
\f1\b0 \cf2  i 
\f2\b \cf5 in
\f1\b0 \cf2  \cf7 `seq 1 357`\cf2 ;\

\f2\b \cf5 do
\f1\b0 \cf2 \

\f2\b \cf5 let
\f1\b0 \cf2  k=(\cf4 100\cf2 *($i\cf4 -1\cf2 ))\cf4 +1\cf2 \

\f2\b \cf5 let
\f1\b0 \cf2  l=(\cf4 100\cf2 *($i\cf4 -1\cf2 ))\cf4 +10\cf2 \
sbatch --array=$k-$l RSimulationCode.sh\

\f2\b \cf5 done\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b0 \cf0 \cb1 23. Following the running of the results, download the results from \'93/pine/scr/s/k/skvanbur/GEUV1/RSimulationCodeRes/\'93 to your computer and run the file \'93RSimsPowerTable.R\'94 in the Tables subdirectory of the Paper folder to create the tables.  All tables within the paper are created by this file but results are saved in a different directory such that if you do update any tables you will need to run the file \'93SyncPaper1FiguresandTables.sh\'94 in the main Paper directory to sync the new versions to the proper location such the updates are included in the paper.\cf2 \cb3 \
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0
\cf2 \
\
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f1 \cf2 \
\pard\tx593\pardeftab593\pardirnatural\partightenfactor0

\f0 \cf0 \cb1 \
}